# Importations essentielles
import pandas as pd
from sklearn.ensemble import IsolationForest
import streamlit as st

# Import des modules
from SVM import train_svm_model, create_confusion_matrix_plot, create_roc_curve_plot, create_precision_recall_plot
from ANN import train_ann_model, create_ann_plots
from XGBoost import (train_xgboost_model, create_xgboost_confusion_matrix_plot, 
                     create_xgboost_roc_curve_plot, create_xgboost_precision_recall_plot, 
                     create_feature_importance_plot)

# Configuration Streamlit
st.set_page_config(page_title="DÃ©tection de Fraude", layout="wide")
st.title("ğŸ” DÃ©tection de Fraude Bancaire")
st.write("""
### Analyse des transactions avec Machine Learning
Cette application dÃ©tecte les opÃ©rations suspectes en utilisant diffÃ©rents algorithmes.
""")

# Chargement des donnÃ©es
@st.cache_data
def load_data():
    return pd.read_csv("creditcard_NettoyÃ©.csv")

# Cache pour les modÃ¨les
@st.cache_data
def get_svm_results(data):
    return train_svm_model(data)

@st.cache_data
def get_ann_results(data):
    return train_ann_model(data)

@st.cache_data
def get_xgboost_results(data):
    return train_xgboost_model(data)

# Interface principale
data = load_data()

# Sidebar pour les informations sur les donnÃ©es
with st.sidebar:
    st.header("ğŸ“Š Informations sur les donnÃ©es")
    st.write(f"**Nombre total de transactions:** {len(data):,}")
    st.write(f"**Transactions normales:** {(data['Class'] == 0).sum():,}")
    st.write(f"**Transactions frauduleuses:** {(data['Class'] == 1).sum():,}")
    st.write(f"**Taux de fraude:** {(data['Class'] == 1).mean()*100:.2f}%")
    
    st.divider()
    
    st.header("ğŸ¤– Algorithmes disponibles")
    st.write("**SVM** - Support Vector Machine")
    st.write("**ANN** - Artificial Neural Network")
    st.write("**XGBoost** - Extreme Gradient Boosting")

# Section principale
col1, col2 = st.columns([2, 1])

with col1:
    # Affichage des donnÃ©es
    if st.checkbox("Afficher les donnÃ©es brutes"):
        st.dataframe(data.head(100), use_container_width=True)

with col2:
    st.write("### ğŸš€ Lancer l'analyse")
    
    # Boutons pour les diffÃ©rents algorithmes
    col_svm, col_ann, col_xgb = st.columns(3)
    
    with col_svm:
        if st.button("ğŸ”µ SVM", type="primary", use_container_width=True):
            with st.spinner('EntraÃ®nement SVM...'):
                try:
                    results = get_svm_results(data)
                    st.success("âœ… SVM terminÃ©!")
                    st.session_state.svm_results = results
                    # Nettoyer les autres rÃ©sultats
                    for key in ['ann_results', 'xgboost_results', 'comparison_mode']:
                        if key in st.session_state:
                            del st.session_state[key]
                except Exception as e:
                    st.error(f"âŒ Erreur SVM : {str(e)}")
    
    with col_ann:
        if st.button("ğŸŸ¢ ANN", type="secondary", use_container_width=True):
            with st.spinner('EntraÃ®nement ANN...'):
                try:
                    results = get_ann_results(data)
                    st.success("âœ… ANN terminÃ©!")
                    st.session_state.ann_results = results
                    # Nettoyer les autres rÃ©sultats
                    for key in ['svm_results', 'xgboost_results', 'comparison_mode']:
                        if key in st.session_state:
                            del st.session_state[key]
                except Exception as e:
                    st.error(f"âŒ Erreur ANN : {str(e)}")
    
    with col_xgb:
        if st.button("ğŸŸ¡ XGBoost", type="secondary", use_container_width=True):
            with st.spinner('EntraÃ®nement XGBoost...'):
                try:
                    results = get_xgboost_results(data)
                    st.success("âœ… XGBoost terminÃ©!")
                    st.session_state.xgboost_results = results
                    # Nettoyer les autres rÃ©sultats
                    for key in ['svm_results', 'ann_results', 'comparison_mode']:
                        if key in st.session_state:
                            del st.session_state[key]
                except Exception as e:
                    st.error(f"âŒ Erreur XGBoost : {str(e)}")
    
    # Bouton pour comparer tous les modÃ¨les
    st.divider()
    if st.button("âš–ï¸ Comparer tous les modÃ¨les", use_container_width=True):
        with st.spinner('EntraÃ®nement de tous les modÃ¨les...'):
            try:
                svm_results = get_svm_results(data)
                ann_results = get_ann_results(data)
                xgboost_results = get_xgboost_results(data)
                
                # Stocker tous les rÃ©sultats
                st.session_state.svm_results = svm_results
                st.session_state.ann_results = ann_results
                st.session_state.xgboost_results = xgboost_results
                st.session_state.comparison_mode = True
                
                st.success("âœ… Comparaison terminÃ©e!")
                
            except Exception as e:
                st.error(f"âŒ Erreur lors de la comparaison : {str(e)}")

# Affichage des rÃ©sultats SVM
if 'svm_results' in st.session_state and 'comparison_mode' not in st.session_state:
    results = st.session_state.svm_results
    
    st.write("## ğŸ”µ RÃ©sultats de l'analyse SVM")
    
    # MÃ©triques principales
    st.write("### ğŸ“ˆ Performances du modÃ¨le")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Exactitude", f"{results['metrics']['accuracy']:.3f}")
    with col2:
        st.metric("PrÃ©cision", f"{results['metrics']['precision']:.3f}")
    with col3:
        st.metric("Rappel", f"{results['metrics']['recall']:.3f}")
    with col4:
        st.metric("F1-Score", f"{results['metrics']['f1']:.3f}")
    
    # Graphiques SVM
    st.write("### ğŸ“Š Visualisations")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**Matrice de Confusion**")
        fig1 = create_confusion_matrix_plot(results['confusion_matrix'])
        st.pyplot(fig1)
    
    with col2:
        st.write("**Courbe ROC**")
        fig2 = create_roc_curve_plot(results['roc_data'], results['metrics']['roc_auc'])
        st.pyplot(fig2)
    
    with col3:
        st.write("**Courbe PrÃ©cision-Rappel**")
        fig3 = create_precision_recall_plot(results['pr_data'], results['metrics']['pr_auc'])
        st.pyplot(fig3)

# Affichage des rÃ©sultats ANN
if 'ann_results' in st.session_state and 'comparison_mode' not in st.session_state:
    results = st.session_state.ann_results
    
    st.write("## ğŸŸ¢ RÃ©sultats de l'analyse ANN (RÃ©seau de Neurones)")
    
    # MÃ©triques principales
    st.write("### ğŸ“ˆ Performances du modÃ¨le")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Exactitude", f"{results['metrics']['accuracy']:.3f}")
    with col2:
        st.metric("PrÃ©cision", f"{results['metrics']['precision']:.3f}")
    with col3:
        st.metric("Rappel", f"{results['metrics']['recall']:.3f}")
    with col4:
        st.metric("F1-Score", f"{results['metrics']['f1']:.3f}")

    # Informations sur le modÃ¨le et les donnÃ©es
    col1, col2 = st.columns(2)
    with col1:
        st.write("### ğŸ§  Architecture du modÃ¨le")
        st.write(f"**Couches cachÃ©es:** {results['model_info']['hidden_layers']}")
        st.write(f"**Fonction d'activation:** {results['model_info']['activation']}")
        st.write(f"**Ã‰poques d'entraÃ®nement:** {results['model_info']['epochs_trained']}")
        st.write(f"**Taille de batch:** {results['model_info']['batch_size']}")
    
    with col2:
        st.write("### ğŸ“‹ Informations d'entraÃ®nement")
        st.write(f"**Ã‰chantillons totaux:** {results['data_info']['total_samples']:,}")
        st.write(f"**Ã‰chantillons d'entraÃ®nement:** {results['data_info']['train_samples']:,}")
        st.write(f"**Ã‰chantillons de validation:** {results['data_info']['val_samples']:,}")
        st.write(f"**Ã‰chantillons de test:** {results['data_info']['test_samples']:,}")

    # MÃ©triques avancÃ©es
    st.write("### ğŸ¯ MÃ©triques avancÃ©es")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("AUC-ROC", f"{results['metrics']['roc_auc']:.4f}")
    with col2:
        st.metric("AUC-PR", f"{results['metrics']['pr_auc']:.4f}")
    with col3:
        st.write(f"**Taux de fraude:** {results['data_info']['fraud_rate']*100:.2f}%")
    
    # Graphiques ANN
    st.write("### ğŸ“Š Visualisations")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Courbes d'apprentissage**")
        fig1 = create_ann_plots(results, 'learning_curves')
        st.pyplot(fig1)
    
    with col2:
        st.write("**Matrice de Confusion**")
        fig2 = create_ann_plots(results, 'confusion_matrix')
        st.pyplot(fig2)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Courbe ROC**")
        fig3 = create_ann_plots(results, 'roc_curve')
        st.pyplot(fig3)
    
    with col2:
        st.write("**Courbe PrÃ©cision-Rappel**")
        fig4 = create_ann_plots(results, 'precision_recall')
        st.pyplot(fig4)

# Affichage des rÃ©sultats XGBoost
if 'xgboost_results' in st.session_state and 'comparison_mode' not in st.session_state:
    results = st.session_state.xgboost_results
    
    st.write("## ğŸŸ¡ RÃ©sultats de l'analyse XGBoost")
    
    # MÃ©triques principales
    st.write("### ğŸ“ˆ Performances du modÃ¨le")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Exactitude", f"{results['metrics']['accuracy']:.3f}")
    with col2:
        st.metric("PrÃ©cision", f"{results['metrics']['precision']:.3f}")
    with col3:
        st.metric("Rappel", f"{results['metrics']['recall']:.3f}")
    with col4:
        st.metric("F1-Score", f"{results['metrics']['f1']:.3f}")
    
    # Informations sur les donnÃ©es utilisÃ©es
    col1, col2 = st.columns(2)
    with col1:
        st.write("### ğŸ“‹ Informations d'entraÃ®nement")
        st.write(f"**Ã‰chantillons totaux:** {results['data_info']['total_samples']:,}")
        st.write(f"**Ã‰chantillons d'entraÃ®nement:** {results['data_info']['train_samples']:,}")
        st.write(f"**Ã‰chantillons de validation:** {results['data_info']['val_samples']:,}")
        st.write(f"**Ã‰chantillons de test:** {results['data_info']['test_samples']:,}")
    
    with col2:
        st.write("### ğŸ¯ MÃ©triques avancÃ©es")
        st.metric("AUC-ROC", f"{results['metrics']['roc_auc']:.4f}")
        st.metric("AUC-PR", f"{results['metrics']['pr_auc']:.4f}")
        st.write(f"**Taux de fraude:** {results['data_info']['fraud_rate']*100:.2f}%")
    
    # Graphiques XGBoost
    st.write("### ğŸ“Š Visualisations")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Matrice de Confusion**")
        fig1 = create_xgboost_confusion_matrix_plot(results['confusion_matrix'])
        st.pyplot(fig1)
    
    with col2:
        st.write("**Courbe ROC**")
        fig2 = create_xgboost_roc_curve_plot(results['roc_data'], results['metrics']['roc_auc'])
        st.pyplot(fig2)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Courbe PrÃ©cision-Rappel**")
        fig3 = create_xgboost_precision_recall_plot(results['pr_data'], results['metrics']['pr_auc'])
        st.pyplot(fig3)
    
    with col2:
        st.write("**Importance des Features**")
        fig4 = create_feature_importance_plot(results['feature_importance'])
        st.pyplot(fig4)
    
    # Rapport de classification dÃ©taillÃ©
    st.write("### ğŸ“„ Rapport de classification dÃ©taillÃ©")
    st.text(results['classification_report'])

# Mode comparaison
if 'comparison_mode' in st.session_state:
    st.write("## âš–ï¸ Comparaison des modÃ¨les")
    
    svm_results = st.session_state.svm_results
    ann_results = st.session_state.ann_results
    xgboost_results = st.session_state.xgboost_results
    
    # Tableau de comparaison des mÃ©triques
    st.write("### ğŸ“Š Comparaison des performances")
    
    comparison_df = pd.DataFrame({
        'MÃ©trique': ['Exactitude', 'PrÃ©cision', 'Rappel', 'F1-Score', 'AUC-ROC', 'AUC-PR'],
        'SVM': [
            svm_results['metrics']['accuracy'],
            svm_results['metrics']['precision'],
            svm_results['metrics']['recall'],
            svm_results['metrics']['f1'],
            svm_results['metrics']['roc_auc'],
            svm_results['metrics']['pr_auc']
        ],
        'ANN': [
            ann_results['metrics']['accuracy'],
            ann_results['metrics']['precision'],
            ann_results['metrics']['recall'],
            ann_results['metrics']['f1'],
            ann_results['metrics']['roc_auc'],
            ann_results['metrics']['pr_auc']
        ],
        'XGBoost': [
            xgboost_results['metrics']['accuracy'],
            xgboost_results['metrics']['precision'],
            xgboost_results['metrics']['recall'],
            xgboost_results['metrics']['f1'],
            xgboost_results['metrics']['roc_auc'],
            xgboost_results['metrics']['pr_auc']
        ]
    })
    
    # Ajouter une colonne "Meilleur"
    comparison_df['Meilleur'] = comparison_df.apply(
        lambda row: 'SVM' if row['SVM'] >= max(row['ANN'], row['XGBoost']) 
        else 'ANN' if row['ANN'] >= row['XGBoost'] 
        else 'XGBoost', axis=1
    )
    
    st.dataframe(comparison_df, use_container_width=True)
    
    # Graphiques comparatifs
    st.write("### ğŸ“ˆ Courbes ROC comparatives")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**SVM**")
        fig1 = create_roc_curve_plot(svm_results['roc_data'], svm_results['metrics']['roc_auc'])
        st.pyplot(fig1)
    
    with col2:
        st.write("**ANN**")
        fig2 = create_ann_plots(ann_results, 'roc_curve')
        st.pyplot(fig2)
    
    with col3:
        st.write("**XGBoost**")
        fig3 = create_xgboost_roc_curve_plot(xgboost_results['roc_data'], xgboost_results['metrics']['roc_auc'])
        st.pyplot(fig3)
    
    # Recommandation basÃ©e sur les rÃ©sultats
    st.write("### ğŸ¯ Recommandation")
    
    # Calculer le score moyen pour chaque modÃ¨le
    svm_avg = sum([svm_results['metrics'][m] for m in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']]) / 5
    ann_avg = sum([ann_results['metrics'][m] for m in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']]) / 5
    xgb_avg = sum([xgboost_results['metrics'][m] for m in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']]) / 5
    
    best_model = max([('SVM', svm_avg), ('ANN', ann_avg), ('XGBoost', xgb_avg)], key=lambda x: x[1])
    
    st.success(f"ğŸ† **ModÃ¨le recommandÃ© : {best_model[0]}** avec un score moyen de {best_model[1]:.4f}")
    
    if st.button("ğŸ—‘ï¸ Effacer la comparaison"):
        for key in ['svm_results', 'ann_results', 'xgboost_results', 'comparison_mode']:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

# Bouton de nettoyage gÃ©nÃ©ral
if any(key in st.session_state for key in ['svm_results', 'ann_results', 'xgboost_results']):
    if st.button("ğŸ—‘ï¸ Effacer tous les rÃ©sultats"):
        for key in ['svm_results', 'ann_results', 'xgboost_results', 'comparison_mode']:
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()